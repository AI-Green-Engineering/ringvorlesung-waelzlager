{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e14820b-0a1a-4908-a1b0-03fff38f68d2",
   "metadata": {},
   "source": [
    "# Wälzlagerfehlerdiagnose mittels Deep Learning\n",
    "\n",
    "Wir wollen mit einem neuronalen Netzwerk folgende zwei Fehler identifizieren:\n",
    "1. Außenringfehler und\n",
    "2. Innenringfehler.\n",
    "\n",
    "Welche Ansätze kennen Sie, um eine Fehlerdiagnose mithilfe von Künstlicher Intelligenz zu erreichen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73296bfd-6166-40d4-9241-33509f72fa4f",
   "metadata": {},
   "source": [
    "## 1. Daten laden und ansehen\n",
    "\n",
    "Zuerst schauen wir uns die Daten an (Quelle: https://www.mfpt.org/fault-data-sets/).\n",
    "\n",
    "Wir haben\n",
    "\n",
    "1. Baseline - Wälzlagerdaten ohne Fehler\n",
    "2. Outerracefault - Wälzlagerdaten mit Außenringfehler\n",
    "3. Innerracefault - Wälzlagerdaten mit Innenringfehler\n",
    "\n",
    "In der nächsten Zelle laden wir die Daten in das Notebook (Shift + Enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0839b5-a68d-4338-be20-608628239f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pywt\n",
    "import math\n",
    "from PIL import Image\n",
    "from matplotlib import colormaps\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the MATLAB file\n",
    "mat_data_baseline1 = loadmat('data/1 - Three Baseline Conditions/baseline_1.mat')\n",
    "mat_data_baseline2 = loadmat('data/1 - Three Baseline Conditions/baseline_2.mat')\n",
    "mat_data_baseline3 = loadmat('data/1 - Three Baseline Conditions/baseline_3.mat')\n",
    "mat_data_outerracefault1 = loadmat('data/2 - Three Outer Race Fault Conditions/OuterRaceFault_1.mat')\n",
    "mat_data_outerracefault2 = loadmat('data/2 - Three Outer Race Fault Conditions/OuterRaceFault_2.mat')\n",
    "mat_data_outerracefault3 = loadmat('data/2 - Three Outer Race Fault Conditions/OuterRaceFault_3.mat')\n",
    "\n",
    "mat_data_outerracefault_vload1 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_1.mat')\n",
    "mat_data_outerracefault_vload2 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_2.mat')\n",
    "mat_data_outerracefault_vload3 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_3.mat')\n",
    "mat_data_outerracefault_vload4 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_4.mat')\n",
    "mat_data_outerracefault_vload5 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_5.mat')\n",
    "mat_data_outerracefault_vload6 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_6.mat')\n",
    "mat_data_outerracefault_vload7 = loadmat('data/3 - Seven More Outer Race Fault Conditions/OuterRaceFault_vload_7.mat')\n",
    "\n",
    "mat_data_innerracefault_vload1 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_1.mat')\n",
    "mat_data_innerracefault_vload2 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_2.mat')\n",
    "mat_data_innerracefault_vload3 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_3.mat')\n",
    "mat_data_innerracefault_vload4 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_4.mat')\n",
    "mat_data_innerracefault_vload5 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_5.mat')\n",
    "mat_data_innerracefault_vload6 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_6.mat')\n",
    "mat_data_innerracefault_vload7 = loadmat('data/4 - Seven Inner Race Fault Conditions/InnerRaceFault_vload_7.mat')\n",
    "\n",
    "# Create DataFrames\n",
    "baseline1 = pd.DataFrame(mat_data_baseline1['bearing']['gs'][0,0], columns=['Signal'])\n",
    "baseline2 = pd.DataFrame(mat_data_baseline2['bearing']['gs'][0,0], columns=['Signal'])\n",
    "baseline3 = pd.DataFrame(mat_data_baseline3['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault1 = pd.DataFrame(mat_data_outerracefault1['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault2 = pd.DataFrame(mat_data_outerracefault2['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault3 = pd.DataFrame(mat_data_outerracefault3['bearing']['gs'][0,0], columns=['Signal'])\n",
    "\n",
    "outerracefault_vload1 = pd.DataFrame(mat_data_outerracefault_vload1['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault_vload2 = pd.DataFrame(mat_data_outerracefault_vload2['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault_vload3 = pd.DataFrame(mat_data_outerracefault_vload3['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault_vload4 = pd.DataFrame(mat_data_outerracefault_vload4['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault_vload5 = pd.DataFrame(mat_data_outerracefault_vload5['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault_vload6 = pd.DataFrame(mat_data_outerracefault_vload6['bearing']['gs'][0,0], columns=['Signal'])\n",
    "outerracefault_vload7 = pd.DataFrame(mat_data_outerracefault_vload7['bearing']['gs'][0,0], columns=['Signal'])\n",
    "\n",
    "innerracefault_vload1 = pd.DataFrame(mat_data_innerracefault_vload1['bearing']['gs'][0,0], columns=['Signal'])\n",
    "innerracefault_vload2 = pd.DataFrame(mat_data_innerracefault_vload2['bearing']['gs'][0,0], columns=['Signal'])\n",
    "innerracefault_vload3 = pd.DataFrame(mat_data_innerracefault_vload3['bearing']['gs'][0,0], columns=['Signal'])\n",
    "innerracefault_vload4 = pd.DataFrame(mat_data_innerracefault_vload4['bearing']['gs'][0,0], columns=['Signal'])\n",
    "innerracefault_vload5 = pd.DataFrame(mat_data_innerracefault_vload5['bearing']['gs'][0,0], columns=['Signal'])\n",
    "innerracefault_vload6 = pd.DataFrame(mat_data_innerracefault_vload6['bearing']['gs'][0,0], columns=['Signal'])\n",
    "innerracefault_vload7 = pd.DataFrame(mat_data_innerracefault_vload7['bearing']['gs'][0,0], columns=['Signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e003d3-a2f9-4d23-a1db-1c470cf3021f",
   "metadata": {},
   "source": [
    "### Aufgabe\n",
    "\n",
    "Nehmen Sie sich etwas Zeit und schauen Sie sich die Daten an.\n",
    "\n",
    "Wählen Sie sich einen Datensatz (zum Beispiel **baseline1**, siehe oben) aus und nutzen Sie folgende Befehle:\n",
    "\n",
    "- .size - Ziegt die Anzahl der Datenpunkte an\n",
    "- .head() - Zeigt die ersten Daten an\n",
    "- .tail() - Zeigt die letzten Daten an\n",
    "- .iloc[from:to] - Zeigt die Daten für den Bereich from - to an.\n",
    "- (für weiterführende Befehle siehe: https://pandas.pydata.org/docs/reference/frame.html)\n",
    "\n",
    "Welche Struktur haben die Daten? Welche Struktur würden Sie erwarten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1c976-513c-4455-9b6c-6e200cf522f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dataset and perform action\n",
    "outerracefault_vload1.iloc[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ad1de-9e75-4d5f-962d-c89f0ed4dfb0",
   "metadata": {},
   "source": [
    "Mit der folgenden Code-Zelle können Sie die Daten grafisch darstellen.\n",
    "\n",
    "### Aufgabe\n",
    "Können Sie anhand der Daten erkennen, dass ein Außenring- oder Innenringfehler vorliegt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48715e-03d6-41ca-9049-5e82ec39b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the plot based on the range slider values\n",
    "usedDataSet = outerracefault1   # change this to use another dataset.\n",
    "min = 1000                   # you can change this value (start of the visualization)\n",
    "max = 11700                 # you can change this value (end of the visualization)\n",
    "\n",
    "def update_plot(x_range):\n",
    "    x_min, x_max = x_range\n",
    "    min = x_min\n",
    "    max = x_max\n",
    "    \n",
    "    # Plot the data within the selected range\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(usedDataSet.Signal.loc[x_min:x_max], color='blue')\n",
    "    #plt.xlim(0, 10)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.xlabel('Datenpunkt')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Vibrationssignal')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create a range slider widget for selecting the x range\n",
    "range_slider = widgets.IntRangeSlider(\n",
    "    value=[min, max],\n",
    "    min=0,\n",
    "    max=585936,\n",
    "    step=100,\n",
    "    description='Range',\n",
    "    continuous_update=True,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Display the range slider and use it to update the plot interactively\n",
    "widgets.interactive(update_plot, x_range=range_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e242a13-33ac-48f2-a8bb-610103771373",
   "metadata": {},
   "source": [
    "### Aufgabe\n",
    "Die Abtastrate des Signals liegt bei 97656 Hz. <br>\n",
    "Das Signal wurde 6 Sekunden lang aufgenommen. <br>\n",
    "Die sogenannte _ball pass frequency_ für den Außenring beträgt ungefähr 80 Hz. <br>\n",
    "Das heißt, 80 mal pro Sekunde erwarten wir eine größere Amplitude im Vibrationssignal. <br>\n",
    "\n",
    "\n",
    "Können Sie das in den Daten bestätigen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694d6da-5a1e-4cab-8194-4ed652e41ab7",
   "metadata": {},
   "source": [
    "## Trainings- und Testdaten erzeugen\n",
    "Um Trainings- und Testdaten zu erzeugen, zerlegen wir den Datensatz (die 6 Sekunden) in kleinere Zeiteinheiten.\n",
    "\n",
    "### Aufgabe\n",
    "Probieren Sie verschiedene Intervalgrößen aus.\n",
    "Welche Unterteilung würden Sie vorschlagen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e0c4f-aa93-4408-98b6-beda320a2e6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usedDataSet = baseline1   # change this to use another dataset.\n",
    "interval = 5000 # CHANGE this value\n",
    "\n",
    "\"\"\"===============================================\"\"\"\n",
    "\n",
    "N = math.floor(len(usedDataSet) / interval)\n",
    "\n",
    "# Define the wavelet and scales\n",
    "wavelet = 'cmor1.5-1.0'  # Complex Morlet wavelet\n",
    "sampling_period = 0.000020\n",
    "scales = np.arange(1,128)# TODO: this needs to be adjusted\n",
    "\n",
    "# Perform CWT\n",
    "coefficients, frequencies = pywt.cwt(usedDataSet['Signal'].loc[:interval], scales, wavelet)\n",
    "\n",
    "usedDataSet[\"s\"] = usedDataSet.index / 97656\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig, axs = plt.subplots(2,1, sharex=True, figsize=(8, 4))\n",
    "\n",
    "# Plot the data within the selected range\n",
    "\n",
    "axs[0].plot(usedDataSet.s.loc[0:interval], usedDataSet.Signal.loc[0:interval], color='blue')\n",
    "axs[0].set_ylabel(\"Amplitude\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot scalogram\n",
    "cax = axs[1].contourf(usedDataSet['s'].loc[:interval], frequencies, abs(coefficients), extend='both', cmap='viridis')\n",
    "axs[1].set_ylabel(\"Frequenz Hz\")\n",
    "axs[1].set_ylim(0.0,0.1)\n",
    "#fig.colorbar(cax, label=\"Magnitude\")\n",
    "\n",
    "\n",
    "plt.xlabel('Zeit in Sekunden')\n",
    "#plt.title('Vibrationssignal mit Außenringschaden')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8ddb2-d567-4cd9-8383-9c6662ca0d88",
   "metadata": {},
   "source": [
    "Wie erzeugen daraus Bilder, die alle auf eine Größe von 227 x 227 Pixeln gebracht werden.\n",
    "\n",
    "### Aufgabe\n",
    "Warum werden die Bilder auf eine einheitliche Größe gebracht?\n",
    "Probieren Sie andere Bildergrößen aus. Können Sie sich Alternativen vorstellen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa6a6c-5bbf-48d6-8110-d62be120a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 227 # CHANGE this value\n",
    "image_height = 227 # CHANGE this value\n",
    "\n",
    "\"\"\"===============================================\"\"\"\n",
    "\n",
    "interval = 5000\n",
    "N = math.floor(len(outerracefault3) / interval)\n",
    "\n",
    "# Define the wavelet and scales\n",
    "wavelet = 'cmor1.5-1.0'  # Complex Morlet wavelet\n",
    "sampling_period = 0.000020\n",
    "scales = np.arange(1,128)# TODO: this needs to be adjusted\n",
    "\n",
    "# Perform CWT\n",
    "coefficients, frequencies = pywt.cwt(outerracefault3['Signal'].loc[:interval], scales, wavelet)\n",
    "cfs = abs(coefficients)\n",
    "flipped_cfs = np.flip(cfs, axis=0)\n",
    "rescaled_cfs = np.round(255 * (flipped_cfs - flipped_cfs.min()) / (flipped_cfs.max() - flipped_cfs.min())).astype(int)\n",
    "\n",
    "colormap = colormaps['jet'].resampled(320)\n",
    "img = colormap(rescaled_cfs / 255.0)[:, :, :3] # rm alpha component\n",
    "img = (img * 255).astype(np.uint8)\n",
    "image = Image.fromarray(img)\n",
    "\n",
    "# Warum wird gerade 227x227 verwendet?\n",
    "resized_image = image.resize((image_width,image_height), Image.Resampling.LANCZOS)\n",
    "resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b02df8-f2cb-4561-81ee-217bbecc7cf8",
   "metadata": {},
   "source": [
    "Das erzeugen aller Bilder braucht relativ viel Zeit, deshalb haben wir das hier schon vorbereitet.\n",
    "\n",
    "### Aufgabe\n",
    "Schauen Sie sich die Struktur und die Bilder in dem Ordner *images* an.\n",
    "\n",
    "Können Sie die Ordnerstruktur erklären?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfef53b-a119-4358-8b8c-3923c0b00cf8",
   "metadata": {},
   "source": [
    "### Hinweis\n",
    "Die folgende Code-Zelle erzeugt die Bilder. Das dauert (je nach Computerleistung) ca. 7 Minuten.\n",
    "Wenn Sie das Beispiel Zuhause nachstellen wollen, führen Sie die Funktion createAllData() (siehe letzte Zeile) aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d930800-ed1a-4f9e-9ac9-bb5c59b50a15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def createData(data, path, filename):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    # Which interval to choose?\n",
    "    interval = 5000\n",
    "    N = math.floor(len(data) / interval)\n",
    "\n",
    "    # Define the wavelet and scales\n",
    "    wavelet = 'cmor1.5-1.0'  # Complex Morlet wavelet\n",
    "    sampling_period = 0.000020\n",
    "    scales = np.arange(1,128)# TODO: this needs to be adjusted\n",
    "\n",
    "    for i in range(N):\n",
    "        # Perform CWT\n",
    "        coefficients, frequencies = pywt.cwt(data['Signal'].loc[i*interval:(i+1)*interval], scales, wavelet)\n",
    "\n",
    "        cfs = abs(coefficients)\n",
    "\n",
    "        flipped_cfs = np.flip(cfs, axis=0)\n",
    "\n",
    "        rescaled_cfs = np.round(255 * (flipped_cfs - flipped_cfs.min()) / (flipped_cfs.max() - flipped_cfs.min())).astype(int)\n",
    "\n",
    "        colormap = colormaps['jet'].resampled(320)\n",
    "        img = colormap(rescaled_cfs / 255.0)[:, :, :3] # rm alpha component\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(img)\n",
    "        # Warum wird gerade 227x227 verwendet?\n",
    "        resized_image = image.resize((227,227), Image.Resampling.LANCZOS)\n",
    "        resized_image.save(f\"{path}/{filename}-{i}.jpg\", \"JPEG\")\n",
    "\n",
    "def createAllData():\n",
    "    createData(baseline1, \"images/train/baseline\", \"baseline1\")\n",
    "    createData(baseline2, \"images/train/baseline\", \"baseline2\")\n",
    "\n",
    "    createData(outerracefault1, \"images/train/outerracefault\", \"outerracefault1\")\n",
    "    createData(outerracefault2, \"images/train/outerracefault\", \"outerracefault2\")\n",
    "    createData(outerracefault_vload1, \"images/train/outerracefault\", \"outerracefault_vload1\")\n",
    "    createData(outerracefault_vload2, \"images/train/outerracefault\", \"outerracefault_vload2\")\n",
    "    createData(outerracefault_vload3, \"images/train/outerracefault\", \"outerracefault_vload3\")\n",
    "    createData(outerracefault_vload4, \"images/train/outerracefault\", \"outerracefault_vload4\")\n",
    "    createData(outerracefault_vload5, \"images/train/outerracefault\", \"outerracefault_vload5\")\n",
    "\n",
    "    createData(innerracefault_vload1, \"images/train/innerracefault\", \"innerracefault_vload1\")\n",
    "    createData(innerracefault_vload2, \"images/train/innerracefault\", \"innerracefault_vload2\")\n",
    "    createData(innerracefault_vload3, \"images/train/innerracefault\", \"innerracefault_vload3\")\n",
    "    createData(innerracefault_vload4, \"images/train/innerracefault\", \"innerracefault_vload4\")\n",
    "    createData(innerracefault_vload5, \"images/train/innerracefault\", \"innerracefault_vload5\")\n",
    "\n",
    "    # create test_data\n",
    "    createData(baseline3, \"images/test/baseline\", \"baseline3\")\n",
    "    createData(outerracefault3, \"images/test/outerracefault\", \"outerracefault3\")\n",
    "\n",
    "    createData(outerracefault_vload6, \"images/test/outerracefault\", \"outerracefault_vload6\")\n",
    "    createData(outerracefault_vload7, \"images/test/outerracefault\", \"outerracefault_vload7\")\n",
    "\n",
    "    createData(innerracefault_vload6, \"images/test/innerracefault\", \"innerracefault_vload6\")\n",
    "    createData(innerracefault_vload7, \"images/test/innerracefault\", \"innerracefault_vload7\")\n",
    "\n",
    "# createAllData()    # uncomment this line to create all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da5087-b4a5-4a28-b0ad-8a8b0706bf48",
   "metadata": {},
   "source": [
    "## Neuronales Netz trainieren\n",
    "\n",
    "Wir nehmen ein vortrainiertes Modell mit dem Namen _SqueezeNet_ (https://en.wikipedia.org/wiki/SqueezeNet).\n",
    "\n",
    "### Aufgabe\n",
    "Welchen Vorteil hat es, ein bereits (vor-)trainiertes Modell zu benutzen?\n",
    "Tragen Sie die Zahl für die Anzahl der Fehlerklassen ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e77f02-b533-447b-82d8-cd18b2383321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3  # ADD this value (number)\n",
    "# Tragen Sie die Anzahl Fehlerklassen in den Code ein\n",
    "\n",
    "\"\"\"===============================================\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "squeezenet = models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.DEFAULT)\n",
    "\n",
    "squeezenet.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "squeezenet.num_classes = num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7984113-97a8-4c94-a887-9389ba68845b",
   "metadata": {},
   "source": [
    "Im nächsten Schritt laden wir die Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9991c-b650-4153-89c8-367f0f58957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32 # You can change this value\n",
    "shuffleTrainingData = True  # You can change this value\n",
    "shuffleTestData = True  # You can change this value\n",
    "\n",
    "folderForTraining = 'images/train'\n",
    "folderForTesting = 'images/test' \n",
    "\n",
    "\"\"\"===============================================\"\"\"\n",
    "\n",
    "# Define transformations for the training and validation datasets\n",
    "transform = transforms.Compose([\n",
    "   # transforms.Resize((224, 224)),  # Resizes the image to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizes the image based on ImageNet statistics\n",
    "])\n",
    "\n",
    "# Load your dataset\n",
    "train_dataset = datasets.ImageFolder(root=folderForTraining, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=folderForTesting, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize, shuffle=shuffleTrainingData)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batchSize, shuffle=shuffleTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72966736-b7a7-4c65-865a-99941d8acea1",
   "metadata": {},
   "source": [
    "Jetzt können wir das Training starten.\n",
    "\n",
    "Zunächst müssen Sie festlegen, wie viele Durchläufe (= Epochen) Sie haben wollen.\n",
    "Legen Sie anschließend die Lernrate fest.\n",
    "\n",
    "ACHTUNG: Je mehr Epochen Sie wählen und je kleiner die Lernrate ist, umso länger braucht das Training. Starten Sie diesen Code, wenn Sie alles eingestellt haben.\n",
    "(8 Epochen, 0.001 = ~6 Minuten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763828da-fb78-4cd7-b6f0-4b6e15314b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 8 # CHANGE this value\n",
    "learnRate = 0.0001 # CHANGE this value\n",
    "\n",
    "\"\"\"===============================================\"\"\"\n",
    "\n",
    "# Specify the loss function and optimizer\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(squeezenet.parameters(), lr=learnRate)\n",
    "\n",
    "\n",
    "# Assuming losses and accuracies are collected during training\n",
    "train_losses = []  # fill these with your training loss values\n",
    "val_accuracies = []  # fill these with your validation accuracy values\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "squeezenet.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    squeezenet.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = squeezenet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    squeezenet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = squeezenet(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "    val_accuracies.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c5c48-4e10-4dc5-bcc5-c0d82e1ae52f",
   "metadata": {},
   "source": [
    "## Ergebnisse visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a54249-f0de-4317-84ab-703d9a27ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss over epochs\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edced506-8571-4084-b02d-f85a7c8c3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch of images from your validation set\n",
    "import numpy as np\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Pass through model\n",
    "outputs = squeezenet(images.to(device))\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Move data to CPU for numpy processing\n",
    "images, preds, labels = images.cpu(), preds.cpu(), labels.cpu()\n",
    "\n",
    "# Display images with predictions\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for idx in np.arange(8):  # visualize first 8 predictions\n",
    "    ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\n",
    "    img = images[idx] / 2 + 0.5  # unnormalize if needed\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))  # convert from Tensor image\n",
    "    ax.set_title(f\"Pred: {preds[idx]} | True: {labels[idx]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab0e0e-277e-4e19-93c6-b3eb67a90e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Gather all predictions and true labels\n",
    "all_preds = torch.tensor([])\n",
    "all_labels = torch.tensor([])\n",
    "\n",
    "# Make predictions on entire validation set\n",
    "squeezenet.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = squeezenet(images.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds = torch.cat((all_preds, preds.cpu()), dim=0)\n",
    "        all_labels = torch.cat((all_labels, labels), dim=0)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels.numpy(), all_preds.numpy())\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=[\"Baseline\",\"Innerrace\",\"Outerrace\"], columns=[\"Baseline\",\"Innerrace\",\"Outerrace\"])\n",
    "\n",
    "#category_mapping = { 'Baseline': 0, 'Innerrace': 1, 'Outerrace': 2 }\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7c43c-488c-48a4-b9fe-df0c16887f1f",
   "metadata": {},
   "source": [
    "## Zusammenfassung"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
